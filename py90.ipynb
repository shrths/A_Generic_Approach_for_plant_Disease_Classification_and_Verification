{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOunting the Drive Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1C4NR3LjFGA",
    "outputId": "2733675b-ac4c-4a46-dbf0-b7273992a459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stfZKkeOnplz",
    "outputId": "f52768e8-32f7-434e-b6b9-2acd44463fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/1a/0d79814736cfecc825ab8094b39648cc9c46af7af1bae839928acb73b4dd/tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2MB)\n",
      "\u001b[K     |████████████████████████████████| 516.2MB 36kB/s \n",
      "\u001b[?25hCollecting keras==2.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 39.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.19.5)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (2.10.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 36.1MB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 40.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.12.4)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.36.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.12.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.32.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
      "Collecting keras-applications>=1.0.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (56.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.10.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.12.5)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.4.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow, keras-applications, keras\n",
      "  Found existing installation: tensorboard 2.4.1\n",
      "    Uninstalling tensorboard-2.4.1:\n",
      "      Successfully uninstalled tensorboard-2.4.1\n",
      "  Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "  Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.3.1 keras-applications-1.0.8 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.2.0 keras==2.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMjtGXm3oN2T",
    "outputId": "7dabaa67-2473-4af1-f0b4-136151d52814"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPpge-4KoQOo",
    "outputId": "93081415-c40b-4c0e-9302-7b099dc82779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "x=!nvidia-smi\n",
    "count=0\n",
    "for i in x:\n",
    "    if \"============\" in i:\n",
    "        count+=1\n",
    "        break\n",
    "    count+=1\n",
    "if 'p100' in x[count].lower():\n",
    "    print(\"found\")\n",
    "else:\n",
    "    print(x[count])\n",
    "    time.sleep(1)\n",
    "    #os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOO0MaJhoT9P"
   },
   "outputs": [],
   "source": [
    "# Resizinig all the images to (224,224)\n",
    "IMAGE_SIZE = [224,224]\n",
    "\n",
    "train_path = '/content/drive/MyDrive/leaf-disease/input/train'\n",
    "test_path = '/content/drive/MyDrive/leaf-disease/input/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Scaling & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5tJZB8ooZf8"
   },
   "outputs": [],
   "source": [
    "# Scaling all the images between 0 to 1\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=False)\n",
    "\n",
    "# Performing only scaling on the test dataset\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYsJkFJpoalf",
    "outputId": "52e5706b-5d9b-4bcf-8c26-972367fcacd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 3 classes.\n",
      "Found 120 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_datagen.flow_from_directory(train_path,\n",
    "                                              target_size=(224,224),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size=(224,224),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmd2ZIJ4ojMy",
    "outputId": "90bd6309-8e5b-44c7-84a2-1aad3c068cac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "vgg19=VGG19(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMwrTp2JopwL",
    "outputId": "706ab270-2b67-45dd-854f-4243adb249fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 75267     \n",
      "=================================================================\n",
      "Total params: 20,099,651\n",
      "Trainable params: 20,099,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x11= Flatten()(vgg19.output)\n",
    "prediction11 = Dense(3, activation='softmax')(x11)\n",
    "model11 = Model(inputs = vgg19.inputs, outputs = prediction11)\n",
    "model11.summary()\n",
    "model11.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4cPjby_osR6",
    "outputId": "a9f2b094-0569-4a37-c9b5-b4d663c1cfe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-5d8621b6d5f5>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 55s 14s/step - loss: 46.3826 - accuracy: 0.4250 - val_loss: 1.1434 - val_accuracy: 0.3333\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.4997 - accuracy: 0.3167 - val_loss: 1.1433 - val_accuracy: 0.3333\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.1354 - accuracy: 0.3583 - val_loss: 1.2702 - val_accuracy: 0.3333\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.3589 - accuracy: 0.3417 - val_loss: 1.1037 - val_accuracy: 0.3333\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.1368 - accuracy: 0.3000 - val_loss: 1.1160 - val_accuracy: 0.3333\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.1355 - accuracy: 0.3333 - val_loss: 1.0984 - val_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "hist = model11.fit_generator(train_set, validation_data=test_set, epochs=20, steps_per_epoch=len(train_set), validation_steps=len(test_set),callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "uTP9uETUovA7",
    "outputId": "ad9183a3-7f9a-4ede-8b65-a7d5e33dc20d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=hist\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDpGLyVFb46c",
    "outputId": "15dc2e81-ef08-4145-9606-bd15317cfccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mob = InceptionV3(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjfeyzbwcAje",
    "outputId": "108e8571-1c8b-4b19-85cc-835f57a815c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 51200)        0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            153603      flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,956,387\n",
      "Trainable params: 21,921,955\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x1= Flatten()(mob.output)\n",
    "prediction1 = Dense(3, activation='softmax')(x1)\n",
    "model12 = Model(inputs = mob.inputs, outputs = prediction1)\n",
    "model12.summary()\n",
    "model12.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZmrZe29cJbc",
    "outputId": "f24eb3d5-624a-47b9-e39b-807a97dbc0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-92f44a830b2e>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 39s 10s/step - loss: 3.5557 - accuracy: 0.5417 - val_loss: 3.6142 - val_accuracy: 0.5500\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.9095 - accuracy: 0.8250 - val_loss: 17.8104 - val_accuracy: 0.3583\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 2s 539ms/step - loss: 0.6818 - accuracy: 0.8917 - val_loss: 64.4027 - val_accuracy: 0.4000\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 3.2550 - accuracy: 0.8500 - val_loss: 159.3355 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 0.8917 - accuracy: 0.8667 - val_loss: 285.7456 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.3269 - accuracy: 0.9250 - val_loss: 340.9417 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 2s 560ms/step - loss: 0.3835 - accuracy: 0.8667 - val_loss: 400.8030 - val_accuracy: 0.3583\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 0.1571 - accuracy: 0.9417 - val_loss: 1362.1460 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.0923 - accuracy: 0.9750 - val_loss: 1608.6598 - val_accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 2s 556ms/step - loss: 0.1094 - accuracy: 0.9750 - val_loss: 1125.9191 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.0677 - accuracy: 0.9917 - val_loss: 570.1067 - val_accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.0973 - accuracy: 0.9667 - val_loss: 305.2072 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 210.1315 - val_accuracy: 0.3417\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 78.8473 - val_accuracy: 0.3917\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 2s 537ms/step - loss: 0.2938 - accuracy: 0.9917 - val_loss: 27.1692 - val_accuracy: 0.6000\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.0636 - accuracy: 0.9750 - val_loss: 7.6103 - val_accuracy: 0.4500\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 2s 540ms/step - loss: 0.0215 - accuracy: 0.9917 - val_loss: 7.8077 - val_accuracy: 0.3750\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.0351 - accuracy: 0.9833 - val_loss: 7.1636 - val_accuracy: 0.3417\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 2s 546ms/step - loss: 0.1326 - accuracy: 0.9750 - val_loss: 2235.8020 - val_accuracy: 0.6000\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 2s 549ms/step - loss: 0.3822 - accuracy: 0.9500 - val_loss: 59069.3906 - val_accuracy: 0.3833\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.7464 - accuracy: 0.9333 - val_loss: 9282.3877 - val_accuracy: 0.3333\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 1.4716 - accuracy: 0.8833 - val_loss: 281.2836 - val_accuracy: 0.3750\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.1837 - accuracy: 0.9333 - val_loss: 731.5394 - val_accuracy: 0.3333\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.1227 - accuracy: 0.9667 - val_loss: 902.4670 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.2933 - accuracy: 0.9583 - val_loss: 195022.6875 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 1.0444 - accuracy: 0.8167 - val_loss: 12247331.0000 - val_accuracy: 0.3333\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 2.2989 - accuracy: 0.7000 - val_loss: 46073300.0000 - val_accuracy: 0.1667\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 2s 555ms/step - loss: 4.4116 - accuracy: 0.7417 - val_loss: 238450800.0000 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 1.6889 - accuracy: 0.7000 - val_loss: 22171748.0000 - val_accuracy: 0.3333\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 2.2936 - accuracy: 0.7917 - val_loss: 243320016.0000 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 2.6704 - accuracy: 0.6917 - val_loss: 1608081664.0000 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 2.5176 - accuracy: 0.7667 - val_loss: 245866784.0000 - val_accuracy: 0.3250\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 2s 557ms/step - loss: 1.8822 - accuracy: 0.8583 - val_loss: 77582288.0000 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 1.5201 - accuracy: 0.8667 - val_loss: 200463184.0000 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 2s 551ms/step - loss: 1.2012 - accuracy: 0.8333 - val_loss: 107737288.0000 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 1.0752 - accuracy: 0.7833 - val_loss: 25020044.0000 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 2s 539ms/step - loss: 0.6690 - accuracy: 0.8250 - val_loss: 35214292.0000 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 1.0776 - accuracy: 0.8667 - val_loss: 54583180.0000 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.2351 - accuracy: 0.9333 - val_loss: 32275340.0000 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 0.2139 - accuracy: 0.9667 - val_loss: 13325483.0000 - val_accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.2339 - accuracy: 0.9333 - val_loss: 4988836.5000 - val_accuracy: 0.3333\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.5271 - accuracy: 0.9167 - val_loss: 2858213.2500 - val_accuracy: 0.3333\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.1962 - accuracy: 0.9667 - val_loss: 2077179.2500 - val_accuracy: 0.3333\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 2s 570ms/step - loss: 0.8425 - accuracy: 0.9167 - val_loss: 1299070.7500 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 2s 550ms/step - loss: 0.2168 - accuracy: 0.9583 - val_loss: 755162.9375 - val_accuracy: 0.3333\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 2s 583ms/step - loss: 0.6670 - accuracy: 0.9750 - val_loss: 156273.4219 - val_accuracy: 0.3333\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.2305 - accuracy: 0.9500 - val_loss: 141260.7969 - val_accuracy: 0.3417\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 2s 571ms/step - loss: 0.3216 - accuracy: 0.9667 - val_loss: 100424.7578 - val_accuracy: 0.3417\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.0634 - accuracy: 0.9917 - val_loss: 49878.8516 - val_accuracy: 0.3750\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 2s 565ms/step - loss: 0.0770 - accuracy: 0.9750 - val_loss: 26452.5371 - val_accuracy: 0.4500\n"
     ]
    }
   ],
   "source": [
    "r1 = model12.fit_generator(train_set, validation_data=test_set, epochs=50, steps_per_epoch=len(train_set), validation_steps=len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=r1\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception ResNet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJ4ZpcxPdBHx",
    "outputId": "5ae08b71-5d17-4742-9394-8f7be554e6a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "inc=InceptionResNetV2(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJQPRGVGddn-"
   },
   "outputs": [],
   "source": [
    "x31 = Flatten()(inc.output)\n",
    "predictionss = Dense(3, activation='softmax')(x31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47SqEuaydeHL",
    "outputId": "bbf56840-9305-41b0-f2c3-92a42453f519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 111, 111, 32) 864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 111, 111, 32) 96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 111, 111, 32) 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 109, 109, 32) 9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 109, 109, 32) 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 109, 109, 32) 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 109, 109, 64) 18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 109, 109, 64) 192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 109, 109, 64) 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 54, 54, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 54, 54, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 54, 54, 80)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 52, 52, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 52, 52, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 52, 52, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 25, 25, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 25, 25, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 25, 25, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 25, 25, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 25, 25, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 25, 25, 48)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 25, 25, 96)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 25, 25, 96)   18432       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 25, 25, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 25, 25, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 25, 25, 64)   12288       average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 25, 25, 96)   288         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 25, 25, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 25, 25, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 25, 25, 64)   192         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 25, 25, 96)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 25, 25, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 25, 25, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 25, 25, 64)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 25, 25, 320)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 25, 25, 32)   96          conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 25, 25, 32)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 25, 25, 48)   13824       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 25, 25, 32)   96          conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 25, 25, 48)   144         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 25, 25, 32)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 25, 25, 48)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 25, 25, 32)   9216        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 25, 25, 64)   27648       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 25, 25, 32)   96          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 25, 25, 32)   96          conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 25, 25, 64)   192         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 25, 25, 32)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 25, 25, 32)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 25, 25, 64)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 25, 25, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 25, 25, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 25, 25, 32)   96          conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 25, 25, 32)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 25, 25, 48)   13824       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 25, 25, 32)   96          conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 25, 25, 48)   144         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 25, 25, 32)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 25, 25, 48)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 25, 25, 32)   9216        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 25, 25, 64)   27648       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 25, 25, 32)   96          conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 25, 25, 32)   96          conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 25, 25, 64)   192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 25, 25, 32)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 25, 25, 32)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 25, 25, 64)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_112[0][0]             \n",
      "                                                                 activation_114[0][0]             \n",
      "                                                                 activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 25, 25, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 25, 25, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 25, 25, 32)   96          conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 25, 25, 32)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 25, 25, 48)   13824       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 25, 25, 32)   96          conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 25, 25, 48)   144         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 25, 25, 32)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 25, 25, 48)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 25, 25, 32)   9216        activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 25, 25, 64)   27648       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 25, 25, 32)   96          conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 25, 25, 32)   96          conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 25, 25, 64)   192         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 25, 25, 32)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 25, 25, 32)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 25, 25, 64)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_118[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 25, 25, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 25, 25, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 25, 25, 32)   96          conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 25, 25, 32)   0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 25, 25, 48)   13824       activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 25, 25, 32)   96          conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 25, 25, 48)   144         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 25, 25, 32)   0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 25, 25, 48)   0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 25, 25, 32)   9216        activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 25, 25, 64)   27648       activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 25, 25, 32)   96          conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 25, 25, 32)   96          conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 25, 25, 64)   192         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 25, 25, 32)   0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 25, 25, 32)   0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 25, 25, 64)   0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_124[0][0]             \n",
      "                                                                 activation_126[0][0]             \n",
      "                                                                 activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 25, 25, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 25, 25, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 25, 25, 32)   96          conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 25, 25, 32)   0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 25, 25, 48)   13824       activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 25, 25, 32)   96          conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 25, 25, 48)   144         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 25, 25, 32)   0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 25, 25, 48)   0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 25, 25, 32)   9216        activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 25, 25, 64)   27648       activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 25, 25, 32)   96          conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 25, 25, 32)   96          conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 25, 25, 64)   192         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 25, 25, 32)   0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 25, 25, 32)   0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 25, 25, 64)   0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_130[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 25, 25, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 25, 25, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 25, 25, 32)   96          conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 25, 25, 32)   0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 25, 25, 48)   13824       activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 25, 25, 32)   96          conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 25, 25, 48)   144         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 25, 25, 32)   0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 25, 25, 48)   0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 25, 25, 32)   9216        activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 25, 25, 64)   27648       activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 25, 25, 32)   96          conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 25, 25, 32)   96          conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 25, 25, 64)   192         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 25, 25, 32)   0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 25, 25, 32)   0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 25, 25, 64)   0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_136[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "                                                                 activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 25, 25, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 25, 25, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 25, 25, 32)   96          conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 25, 25, 32)   0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 25, 25, 48)   13824       activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 25, 25, 32)   96          conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 25, 25, 48)   144         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 25, 25, 32)   0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 25, 25, 48)   0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 25, 25, 32)   9216        activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 25, 25, 64)   27648       activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 25, 25, 32)   96          conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 25, 25, 32)   96          conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 25, 25, 64)   192         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 25, 25, 32)   0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 25, 25, 32)   0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 25, 25, 64)   0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_142[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 25, 25, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 25, 25, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 25, 25, 32)   96          conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 25, 25, 32)   0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 25, 25, 48)   13824       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 25, 25, 32)   96          conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 25, 25, 48)   144         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 25, 25, 32)   0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 25, 25, 48)   0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 25, 25, 32)   9216        activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 25, 25, 64)   27648       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 25, 25, 32)   96          conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 25, 25, 32)   96          conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 25, 25, 64)   192         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 25, 25, 32)   0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 25, 25, 32)   0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 25, 25, 64)   0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_148[0][0]             \n",
      "                                                                 activation_150[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 25, 25, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 25, 25, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 25, 25, 32)   96          conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 25, 25, 32)   0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 25, 25, 48)   13824       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 25, 25, 32)   96          conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 25, 25, 48)   144         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 25, 25, 32)   0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 25, 25, 48)   0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 25, 25, 32)   9216        activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 25, 25, 64)   27648       activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 25, 25, 32)   96          conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 25, 25, 32)   96          conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 25, 25, 64)   192         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 25, 25, 32)   0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 25, 25, 32)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 25, 25, 64)   0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_154[0][0]             \n",
      "                                                                 activation_156[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 25, 25, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 25, 25, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 25, 25, 32)   96          conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 25, 25, 32)   0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 25, 25, 48)   13824       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 25, 25, 32)   96          conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 25, 25, 48)   144         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 25, 25, 32)   0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 25, 25, 48)   0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 25, 25, 32)   9216        activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 25, 25, 64)   27648       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 25, 25, 32)   96          conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 25, 25, 32)   96          conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 25, 25, 64)   192         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 25, 25, 32)   0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 25, 25, 32)   0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 25, 25, 64)   0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 25, 25, 128)  0           activation_160[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 25, 25, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 25, 25, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 25, 25, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 25, 25, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 25, 25, 256)  768         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 25, 25, 256)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 25, 25, 256)  589824      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 25, 25, 256)  768         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 25, 25, 256)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 12, 12, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 12, 12, 384)  884736      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 12, 12, 384)  1152        conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 12, 12, 384)  1152        conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 12, 12, 384)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 12, 12, 384)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 12, 12, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 12, 12, 1088) 0           activation_166[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 12, 12, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 12, 12, 128)  384         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 12, 12, 128)  0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 12, 12, 160)  143360      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 12, 12, 160)  480         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 12, 12, 160)  0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 12, 12, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 12, 12, 192)  215040      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 12, 12, 192)  576         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 12, 12, 192)  576         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 12, 12, 192)  0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 12, 12, 192)  0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_170[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 12, 12, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 12, 12, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 12, 12, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 12, 12, 128)  384         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 12, 12, 128)  0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 12, 12, 160)  143360      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 12, 12, 160)  480         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 12, 12, 160)  0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 12, 12, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 12, 12, 192)  215040      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 12, 12, 192)  576         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 12, 12, 192)  576         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 12, 12, 192)  0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 12, 12, 192)  0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_174[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 12, 12, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 12, 12, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 12, 12, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 12, 12, 128)  384         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 12, 12, 128)  0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 12, 12, 160)  143360      activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 12, 12, 160)  480         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 12, 12, 160)  0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 12, 12, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 12, 12, 192)  215040      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 12, 12, 192)  576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 12, 12, 192)  576         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 12, 12, 192)  0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 12, 12, 192)  0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_178[0][0]             \n",
      "                                                                 activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 12, 12, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 12, 12, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 12, 12, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 12, 12, 128)  384         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 12, 12, 128)  0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 12, 12, 160)  143360      activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 12, 12, 160)  480         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 12, 12, 160)  0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 12, 12, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 12, 12, 192)  215040      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 12, 12, 192)  576         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 12, 12, 192)  576         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 12, 12, 192)  0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 12, 12, 192)  0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_182[0][0]             \n",
      "                                                                 activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 12, 12, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 12, 12, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 12, 12, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 12, 12, 128)  384         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 12, 12, 128)  0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 12, 12, 160)  143360      activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 12, 12, 160)  480         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 12, 12, 160)  0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 12, 12, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 12, 12, 192)  215040      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 12, 12, 192)  576         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 12, 12, 192)  576         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 12, 12, 192)  0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 12, 12, 192)  0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_186[0][0]             \n",
      "                                                                 activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 12, 12, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 12, 12, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 12, 12, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 12, 12, 128)  384         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 12, 12, 128)  0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 12, 12, 160)  143360      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 12, 12, 160)  480         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 12, 12, 160)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 12, 12, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 12, 12, 192)  215040      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 12, 12, 192)  576         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 12, 12, 192)  576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 12, 12, 192)  0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 12, 12, 192)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_190[0][0]             \n",
      "                                                                 activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 12, 12, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 12, 12, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 12, 12, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 12, 12, 128)  384         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 12, 12, 128)  0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 12, 12, 160)  143360      activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 12, 12, 160)  480         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 12, 12, 160)  0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 12, 12, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 12, 12, 192)  215040      activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 12, 12, 192)  576         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 12, 12, 192)  576         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 12, 12, 192)  0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 12, 12, 192)  0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_194[0][0]             \n",
      "                                                                 activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 12, 12, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 12, 12, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 12, 12, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 12, 12, 128)  384         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 12, 12, 128)  0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 12, 12, 160)  143360      activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 12, 12, 160)  480         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 12, 12, 160)  0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 12, 12, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 12, 12, 192)  215040      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 12, 12, 192)  576         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 12, 12, 192)  576         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 12, 12, 192)  0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 12, 12, 192)  0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_198[0][0]             \n",
      "                                                                 activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 12, 12, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 12, 12, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 12, 12, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 12, 12, 128)  384         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 12, 12, 128)  0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 12, 12, 160)  143360      activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 12, 12, 160)  480         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 12, 12, 160)  0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 12, 12, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 12, 12, 192)  215040      activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 12, 12, 192)  576         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 12, 12, 192)  576         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 12, 12, 192)  0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 12, 12, 192)  0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 12, 12, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 12, 12, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 12, 12, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 12, 12, 128)  384         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 12, 12, 128)  0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 12, 12, 160)  143360      activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 12, 12, 160)  480         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 12, 12, 160)  0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 12, 12, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 12, 12, 192)  215040      activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 12, 12, 192)  576         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 12, 12, 192)  576         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 12, 12, 192)  0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 12, 12, 192)  0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_206[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 12, 12, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 12, 12, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 12, 12, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 12, 12, 128)  384         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 12, 12, 128)  0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 12, 12, 160)  143360      activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 12, 12, 160)  480         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 12, 12, 160)  0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 12, 12, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 12, 12, 192)  215040      activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 12, 12, 192)  576         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 12, 12, 192)  576         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 12, 12, 192)  0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 12, 12, 192)  0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_210[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 12, 12, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 12, 12, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 12, 12, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 12, 12, 128)  384         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 12, 12, 128)  0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 12, 12, 160)  143360      activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 12, 12, 160)  480         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 12, 12, 160)  0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 12, 12, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 12, 12, 192)  215040      activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 12, 12, 192)  576         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 12, 12, 192)  576         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 12, 12, 192)  0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 12, 12, 192)  0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 12, 12, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 12, 12, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 12, 12, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 12, 12, 128)  384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 12, 12, 128)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 12, 12, 160)  143360      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 12, 12, 160)  480         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 12, 12, 160)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 12, 12, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 12, 12, 192)  215040      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 12, 12, 192)  576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 12, 12, 192)  576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 12, 12, 192)  0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 12, 12, 192)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 12, 12, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 12, 12, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 12, 12, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 12, 12, 128)  384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 12, 12, 128)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 12, 12, 160)  143360      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 12, 12, 160)  480         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 12, 12, 160)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 12, 12, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 12, 12, 192)  215040      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 12, 12, 192)  576         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 12, 12, 192)  576         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 12, 12, 192)  0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 12, 12, 192)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_222[0][0]             \n",
      "                                                                 activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 12, 12, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 12, 12, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 12, 12, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 12, 12, 128)  384         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 12, 12, 128)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 12, 12, 160)  143360      activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 12, 12, 160)  480         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 12, 12, 160)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 12, 12, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 12, 12, 192)  215040      activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 12, 12, 192)  576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 12, 12, 192)  576         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 12, 12, 192)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 12, 12, 192)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_226[0][0]             \n",
      "                                                                 activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 12, 12, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 12, 12, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 12, 12, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 12, 12, 128)  384         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 12, 12, 128)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 12, 12, 160)  143360      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 12, 12, 160)  480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 12, 12, 160)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 12, 12, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 12, 12, 192)  215040      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 12, 12, 192)  576         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 12, 12, 192)  576         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 12, 12, 192)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 12, 12, 192)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_230[0][0]             \n",
      "                                                                 activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 12, 12, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 12, 12, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 12, 12, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 12, 12, 128)  384         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 12, 12, 128)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 12, 12, 160)  143360      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 12, 12, 160)  480         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 12, 12, 160)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 12, 12, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 12, 12, 192)  215040      activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 12, 12, 192)  576         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 12, 12, 192)  576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 12, 12, 192)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 12, 12, 192)  0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_234[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 12, 12, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 12, 12, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 12, 12, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 12, 12, 128)  384         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 12, 12, 128)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 12, 12, 160)  143360      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 12, 12, 160)  480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 12, 12, 160)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 12, 12, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 12, 12, 192)  215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 12, 12, 192)  576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 12, 12, 192)  576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 12, 12, 192)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 12, 12, 192)  0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 12, 12, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 12, 12, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 12, 12, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 12, 12, 128)  384         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 12, 12, 128)  0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 12, 12, 160)  143360      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 12, 12, 160)  480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 12, 12, 160)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 12, 12, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 12, 12, 192)  215040      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 12, 12, 192)  576         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 12, 12, 192)  576         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 12, 12, 192)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 12, 12, 192)  0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_242[0][0]             \n",
      "                                                                 activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 12, 12, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 12, 12, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 12, 12, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 12, 12, 128)  384         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 12, 12, 128)  0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 12, 12, 160)  143360      activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 12, 12, 160)  480         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 12, 12, 160)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 12, 12, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 12, 12, 192)  215040      activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 12, 12, 192)  576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 12, 12, 192)  576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 12, 12, 192)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 12, 12, 192)  0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_246[0][0]             \n",
      "                                                                 activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 12, 12, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 12, 12, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 12, 12, 256)  768         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 12, 12, 256)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 12, 12, 288)  663552      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 12, 12, 256)  768         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 12, 12, 256)  768         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 12, 12, 288)  864         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 12, 12, 256)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 12, 12, 256)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 12, 12, 288)  0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 5, 5, 384)    884736      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 5, 5, 288)    663552      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 5, 5, 320)    829440      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 5, 5, 384)    1152        conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 5, 5, 288)    864         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 5, 5, 320)    960         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 5, 5, 384)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 5, 5, 288)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 5, 5, 320)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 5, 5, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 5, 5, 2080)   0           activation_251[0][0]             \n",
      "                                                                 activation_253[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 5, 5, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 5, 5, 192)    576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 5, 5, 192)    0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 5, 5, 224)    129024      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 5, 5, 224)    672         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 5, 5, 224)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 5, 5, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 5, 5, 256)    172032      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 5, 5, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 5, 5, 256)    768         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 5, 5, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 5, 5, 256)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_257[0][0]             \n",
      "                                                                 activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 5, 5, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 5, 5, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 5, 5, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 5, 5, 192)    576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 5, 5, 192)    0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 5, 5, 224)    129024      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 5, 5, 224)    672         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 5, 5, 224)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 5, 5, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 5, 5, 256)    172032      activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 5, 5, 192)    576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 5, 5, 256)    768         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 5, 5, 192)    0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 5, 5, 256)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_261[0][0]             \n",
      "                                                                 activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 5, 5, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 5, 5, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 5, 5, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 5, 5, 192)    576         conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 5, 5, 192)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 5, 5, 224)    129024      activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 5, 5, 224)    672         conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 5, 5, 224)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 5, 5, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 5, 5, 256)    172032      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 5, 5, 192)    576         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 5, 5, 256)    768         conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 5, 5, 192)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 5, 5, 256)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_265[0][0]             \n",
      "                                                                 activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 5, 5, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 5, 5, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 5, 5, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 5, 5, 192)    576         conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 5, 5, 192)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 5, 5, 224)    129024      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 5, 5, 224)    672         conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 5, 5, 224)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 5, 5, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 5, 5, 256)    172032      activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 5, 5, 192)    576         conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 5, 5, 256)    768         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 5, 5, 192)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 5, 5, 256)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_269[0][0]             \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 5, 5, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 5, 5, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 5, 5, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 5, 5, 192)    576         conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 5, 5, 192)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 5, 5, 224)    129024      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 5, 5, 224)    672         conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 5, 5, 224)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 5, 5, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 5, 5, 256)    172032      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 5, 5, 192)    576         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 5, 5, 256)    768         conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 5, 5, 192)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 5, 5, 256)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_273[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 5, 5, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 5, 5, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 5, 5, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 5, 5, 192)    576         conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 5, 5, 192)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 5, 5, 224)    129024      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 5, 5, 224)    672         conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 5, 5, 224)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 5, 5, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 5, 5, 256)    172032      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 5, 5, 192)    576         conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 5, 5, 256)    768         conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 5, 5, 192)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 5, 5, 256)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_277[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 5, 5, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 5, 5, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 5, 5, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 5, 5, 192)    576         conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 5, 5, 192)    0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 5, 5, 224)    129024      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 5, 5, 224)    672         conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 5, 5, 224)    0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 5, 5, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 5, 5, 256)    172032      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 5, 5, 192)    576         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 5, 5, 256)    768         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 5, 5, 192)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 5, 5, 256)    0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_281[0][0]             \n",
      "                                                                 activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 5, 5, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 5, 5, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 5, 5, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 5, 5, 192)    576         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 5, 5, 192)    0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 5, 5, 224)    129024      activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 5, 5, 224)    672         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 5, 5, 224)    0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 5, 5, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 5, 5, 256)    172032      activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 5, 5, 192)    576         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 5, 5, 256)    768         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 5, 5, 192)    0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 5, 5, 256)    0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_285[0][0]             \n",
      "                                                                 activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 5, 5, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 5, 5, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 5, 5, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 5, 5, 192)    576         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 5, 5, 192)    0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 5, 5, 224)    129024      activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 5, 5, 224)    672         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 5, 5, 224)    0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 5, 5, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 5, 5, 256)    172032      activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 5, 5, 192)    576         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 5, 5, 256)    768         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 5, 5, 192)    0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 5, 5, 256)    0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_289[0][0]             \n",
      "                                                                 activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 5, 5, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 5, 5, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 5, 5, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 5, 5, 192)    576         conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 5, 5, 192)    0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 5, 5, 224)    129024      activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 5, 5, 224)    672         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 5, 5, 224)    0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 5, 5, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 5, 5, 256)    172032      activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 5, 5, 192)    576         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 5, 5, 256)    768         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 5, 5, 192)    0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 5, 5, 256)    0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 5, 5, 448)    0           activation_293[0][0]             \n",
      "                                                                 activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 5, 5, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 5, 5, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 5, 5, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 5, 5, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 5, 5, 1536)   0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 38400)        0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            115203      flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 54,451,939\n",
      "Trainable params: 54,391,395\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelss = Model(inputs = inc.inputs, outputs = predictionss)\n",
    "modelss.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tqd4h7wYdfzq",
    "outputId": "5096f8d2-4a7d-4dbd-fa2b-6efe44fd14c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 3.3093 - accuracy: 0.4250 - val_loss: 15.3923 - val_accuracy: 0.3750\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 1.6039 - accuracy: 0.8167 - val_loss: 5.2980 - val_accuracy: 0.6000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.5258 - accuracy: 0.8917 - val_loss: 3.0539 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.2622 - accuracy: 0.9500 - val_loss: 9.5752 - val_accuracy: 0.3333\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.5708 - accuracy: 0.9333 - val_loss: 439.3525 - val_accuracy: 0.3333\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.2590 - accuracy: 0.9667 - val_loss: 955.9320 - val_accuracy: 0.3417\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0620 - accuracy: 0.9750 - val_loss: 99.6557 - val_accuracy: 0.3917\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0347 - accuracy: 0.9833 - val_loss: 73.1678 - val_accuracy: 0.3333\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0150 - accuracy: 0.9917 - val_loss: 53.2623 - val_accuracy: 0.3333\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0880 - accuracy: 0.9833 - val_loss: 30.6426 - val_accuracy: 0.4667\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0746 - accuracy: 0.9750 - val_loss: 23.7918 - val_accuracy: 0.4333\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.1193 - accuracy: 0.9667 - val_loss: 27.6110 - val_accuracy: 0.3667\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.1301 - accuracy: 0.9583 - val_loss: 17.0856 - val_accuracy: 0.3500\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0247 - accuracy: 0.9833 - val_loss: 12.1910 - val_accuracy: 0.4750\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0484 - accuracy: 0.9833 - val_loss: 10.8627 - val_accuracy: 0.6500\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.1153 - accuracy: 0.9833 - val_loss: 101.1754 - val_accuracy: 0.6083\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0863 - accuracy: 0.9833 - val_loss: 91.2385 - val_accuracy: 0.5667\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.1511 - accuracy: 0.9500 - val_loss: 71.9383 - val_accuracy: 0.5417\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0815 - accuracy: 0.9833 - val_loss: 59.2452 - val_accuracy: 0.6000\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0321 - accuracy: 0.9917 - val_loss: 76.7539 - val_accuracy: 0.6167\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0614 - accuracy: 0.9750 - val_loss: 53.1760 - val_accuracy: 0.5833\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0707 - accuracy: 0.9667 - val_loss: 37.2179 - val_accuracy: 0.5750\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.0424 - accuracy: 0.9917 - val_loss: 92.4998 - val_accuracy: 0.6583\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 0.0187 - accuracy: 0.9917 - val_loss: 114.8345 - val_accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 109.8635 - val_accuracy: 0.6750\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0104 - accuracy: 0.9917 - val_loss: 78.9833 - val_accuracy: 0.6917\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 0.0092 - accuracy: 0.9917 - val_loss: 58.8026 - val_accuracy: 0.7000\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 45.2947 - val_accuracy: 0.7167\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 33.6346 - val_accuracy: 0.7167\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 23.9864 - val_accuracy: 0.7250\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 0.0397 - accuracy: 0.9917 - val_loss: 17.2215 - val_accuracy: 0.7167\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.0184 - accuracy: 0.9917 - val_loss: 14.1969 - val_accuracy: 0.6583\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.3195 - accuracy: 0.9833 - val_loss: 19.1344 - val_accuracy: 0.6167\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.3040 - accuracy: 0.9667 - val_loss: 8.8197 - val_accuracy: 0.7583\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.1457 - accuracy: 0.9417 - val_loss: 2.4652 - val_accuracy: 0.8417\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0898 - accuracy: 0.9917 - val_loss: 9.2735 - val_accuracy: 0.8667\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.1322 - accuracy: 0.9833 - val_loss: 48.9851 - val_accuracy: 0.8083\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 0.0458 - accuracy: 0.9833 - val_loss: 157.6875 - val_accuracy: 0.7500\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0595 - accuracy: 0.9917 - val_loss: 344.4123 - val_accuracy: 0.6917\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0306 - accuracy: 0.9833 - val_loss: 242.4431 - val_accuracy: 0.7000\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 168.7815 - val_accuracy: 0.7000\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 131.5123 - val_accuracy: 0.7167\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0384 - accuracy: 0.9917 - val_loss: 81.1500 - val_accuracy: 0.7667\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 0.0193 - accuracy: 0.9917 - val_loss: 26.7225 - val_accuracy: 0.8250\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0191 - accuracy: 0.9917 - val_loss: 8.2823 - val_accuracy: 0.8750\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.0131 - accuracy: 0.9917 - val_loss: 1.8371 - val_accuracy: 0.9417\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9750\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0083 - accuracy: 0.9917 - val_loss: 0.0455 - val_accuracy: 0.9833\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9833\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 0.0667 - accuracy: 0.9917 - val_loss: 0.0332 - val_accuracy: 0.9833\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9667\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9500\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0285 - accuracy: 0.9917 - val_loss: 0.0299 - val_accuracy: 0.9917\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0396 - accuracy: 0.9917 - val_loss: 0.0361 - val_accuracy: 0.9917\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9583\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9417\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9500\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9583\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9833\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9833\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9833\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 8.9559e-04 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9500\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 2.9820e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9833\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 7.7362e-04 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 1.6507e-04 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 9.0138e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 3.4203e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 3.3904e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 1.8929e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 8.7462e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 2.7478e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 6.3280e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 5.7137e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9917\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 4.2398e-04 - accuracy: 1.0000 - val_loss: 3.4962e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.7390e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 5.9178e-05 - accuracy: 1.0000 - val_loss: 1.8925e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.1625e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0107e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.2523e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 6.4931e-05 - accuracy: 1.0000 - val_loss: 3.3755e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 4.5567e-05 - accuracy: 1.0000 - val_loss: 4.6862e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 1.5969e-04 - accuracy: 1.0000 - val_loss: 5.5664e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 4.5078e-06 - accuracy: 1.0000 - val_loss: 5.9630e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 1.9997e-05 - accuracy: 1.0000 - val_loss: 5.9633e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 8.6947e-05 - accuracy: 1.0000 - val_loss: 5.6904e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 1.6970e-04 - accuracy: 1.0000 - val_loss: 5.0151e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 1.3175e-04 - accuracy: 1.0000 - val_loss: 4.3045e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 8.1931e-06 - accuracy: 1.0000 - val_loss: 3.7587e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 3.3576e-05 - accuracy: 1.0000 - val_loss: 3.2410e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 5.0727e-06 - accuracy: 1.0000 - val_loss: 2.7689e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 8.2048e-06 - accuracy: 1.0000 - val_loss: 2.3743e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 3.3791e-05 - accuracy: 1.0000 - val_loss: 2.0497e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 9.7923e-05 - accuracy: 1.0000 - val_loss: 1.7175e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 1.9089e-05 - accuracy: 1.0000 - val_loss: 1.4513e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 2.0465e-05 - accuracy: 1.0000 - val_loss: 1.2488e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 4.8814e-06 - accuracy: 1.0000 - val_loss: 1.0842e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 2.7494e-05 - accuracy: 1.0000 - val_loss: 9.1555e-05 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 7.9870e-04 - accuracy: 1.0000 - val_loss: 3.3441e-05 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 4.4808e-05 - accuracy: 1.0000 - val_loss: 1.7297e-05 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 1.0898e-05 - accuracy: 1.0000 - val_loss: 1.0969e-05 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 3.5334e-06 - accuracy: 1.0000 - val_loss: 7.9555e-06 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 5.9037e-05 - accuracy: 1.0000 - val_loss: 6.3638e-06 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 2.9965e-05 - accuracy: 1.0000 - val_loss: 5.3101e-06 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 7.4022e-06 - accuracy: 1.0000 - val_loss: 4.6139e-06 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 3.4410e-06 - accuracy: 1.0000 - val_loss: 4.0736e-06 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 4.7908e-06 - accuracy: 1.0000 - val_loss: 3.6267e-06 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 6.9351e-06 - accuracy: 1.0000 - val_loss: 3.2403e-06 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 9.1457e-05 - accuracy: 1.0000 - val_loss: 2.9413e-06 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 6.1744e-04 - accuracy: 1.0000 - val_loss: 2.5390e-06 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 7.7762e-06 - accuracy: 1.0000 - val_loss: 2.2321e-06 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 7.2026e-06 - accuracy: 1.0000 - val_loss: 1.9987e-06 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 8.7481e-05 - accuracy: 1.0000 - val_loss: 1.7861e-06 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 4.8722e-06 - accuracy: 1.0000 - val_loss: 1.6301e-06 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 2.8102e-06 - accuracy: 1.0000 - val_loss: 1.5109e-06 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 1.6615e-05 - accuracy: 1.0000 - val_loss: 1.3927e-06 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 3.4270e-06 - accuracy: 1.0000 - val_loss: 1.2974e-06 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 6.2422e-06 - accuracy: 1.0000 - val_loss: 1.2119e-06 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 6.0820e-06 - accuracy: 1.0000 - val_loss: 1.1305e-06 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 9.5818e-06 - accuracy: 1.0000 - val_loss: 1.0619e-06 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 2.4089e-06 - accuracy: 1.0000 - val_loss: 9.8744e-07 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 1.6897e-06 - accuracy: 1.0000 - val_loss: 9.2485e-07 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 5.4760e-06 - accuracy: 1.0000 - val_loss: 8.7518e-07 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 1.8903e-06 - accuracy: 1.0000 - val_loss: 8.3545e-07 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 1.8040e-06 - accuracy: 1.0000 - val_loss: 7.9273e-07 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 1.0612e-04 - accuracy: 1.0000 - val_loss: 7.5300e-07 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 1.3926e-05 - accuracy: 1.0000 - val_loss: 7.1922e-07 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 7.3810e-07 - accuracy: 1.0000 - val_loss: 6.7949e-07 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 2.2271e-06 - accuracy: 1.0000 - val_loss: 6.5068e-07 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 6.1744e-06 - accuracy: 1.0000 - val_loss: 6.3280e-07 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 2.3741e-06 - accuracy: 1.0000 - val_loss: 6.0995e-07 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 2.2698e-06 - accuracy: 1.0000 - val_loss: 5.8313e-07 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 1.3599e-05 - accuracy: 1.0000 - val_loss: 5.5929e-07 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 2.7963e-05 - accuracy: 1.0000 - val_loss: 5.3942e-07 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 1.7886e-05 - accuracy: 1.0000 - val_loss: 5.1856e-07 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 3.4629e-05 - accuracy: 1.0000 - val_loss: 4.9770e-07 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 2.0404e-06 - accuracy: 1.0000 - val_loss: 4.8180e-07 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 4.4601e-06 - accuracy: 1.0000 - val_loss: 4.6491e-07 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 2.3666e-05 - accuracy: 1.0000 - val_loss: 4.5299e-07 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 1.7006e-06 - accuracy: 1.0000 - val_loss: 4.4008e-07 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 3.9701e-06 - accuracy: 1.0000 - val_loss: 4.2418e-07 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 3.8154e-06 - accuracy: 1.0000 - val_loss: 4.1624e-07 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 5.4949e-06 - accuracy: 1.0000 - val_loss: 4.0332e-07 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 1.8001e-05 - accuracy: 1.0000 - val_loss: 3.9538e-07 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 4.3140e-06 - accuracy: 1.0000 - val_loss: 3.8743e-07 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 6.8148e-07 - accuracy: 1.0000 - val_loss: 3.7948e-07 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 6.6260e-06 - accuracy: 1.0000 - val_loss: 3.7153e-07 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 1.2725e-06 - accuracy: 1.0000 - val_loss: 3.6061e-07 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 6.5173e-06 - accuracy: 1.0000 - val_loss: 3.5365e-07 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 7.6129e-06 - accuracy: 1.0000 - val_loss: 3.5266e-07 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 1.7334e-06 - accuracy: 1.0000 - val_loss: 3.4769e-07 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 5.5687e-06 - accuracy: 1.0000 - val_loss: 3.4372e-07 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 1.5683e-05 - accuracy: 1.0000 - val_loss: 3.4173e-07 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 2.8017e-05 - accuracy: 1.0000 - val_loss: 3.3279e-07 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 2.9993e-05 - accuracy: 1.0000 - val_loss: 3.2186e-07 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 1.0282e-06 - accuracy: 1.0000 - val_loss: 3.1392e-07 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 1.0051e-05 - accuracy: 1.0000 - val_loss: 3.0498e-07 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 3.3188e-06 - accuracy: 1.0000 - val_loss: 3.0100e-07 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 4.4204e-06 - accuracy: 1.0000 - val_loss: 2.9504e-07 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 7.8311e-06 - accuracy: 1.0000 - val_loss: 2.9007e-07 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 5.9617e-06 - accuracy: 1.0000 - val_loss: 2.8908e-07 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 1.3510e-06 - accuracy: 1.0000 - val_loss: 2.8610e-07 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 3.6754e-06 - accuracy: 1.0000 - val_loss: 2.7915e-07 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 1.4980e-06 - accuracy: 1.0000 - val_loss: 2.7617e-07 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 2.7297e-06 - accuracy: 1.0000 - val_loss: 2.7418e-07 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 1.0012e-05 - accuracy: 1.0000 - val_loss: 2.7021e-07 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 5.2092e-06 - accuracy: 1.0000 - val_loss: 2.6226e-07 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 1.4702e-06 - accuracy: 1.0000 - val_loss: 2.5829e-07 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 4.6836e-04 - accuracy: 1.0000 - val_loss: 2.5431e-07 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 1.3970e-05 - accuracy: 1.0000 - val_loss: 2.5729e-07 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 8.5821e-04 - accuracy: 1.0000 - val_loss: 2.2650e-07 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 1.5388e-06 - accuracy: 1.0000 - val_loss: 2.2153e-07 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 7.6562e-06 - accuracy: 1.0000 - val_loss: 2.2352e-07 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 3.1834e-05 - accuracy: 1.0000 - val_loss: 2.2451e-07 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 4.3140e-06 - accuracy: 1.0000 - val_loss: 2.2848e-07 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 3.0880e-05 - accuracy: 1.0000 - val_loss: 2.2650e-07 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 4.6090e-06 - accuracy: 1.0000 - val_loss: 2.2352e-07 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 1.0143e-06 - accuracy: 1.0000 - val_loss: 2.2352e-07 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 6.8179e-05 - accuracy: 1.0000 - val_loss: 2.1954e-07 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 1.0929e-04 - accuracy: 1.0000 - val_loss: 2.2252e-07 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 3.7289e-06 - accuracy: 1.0000 - val_loss: 2.2054e-07 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 3.7480e-06 - accuracy: 1.0000 - val_loss: 2.2252e-07 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 1.8705e-06 - accuracy: 1.0000 - val_loss: 2.2153e-07 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 1.6480e-06 - accuracy: 1.0000 - val_loss: 2.2054e-07 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 1.8757e-05 - accuracy: 1.0000 - val_loss: 2.1756e-07 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 5.7816e-07 - accuracy: 1.0000 - val_loss: 2.1259e-07 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 2.2162e-06 - accuracy: 1.0000 - val_loss: 2.0862e-07 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 2.1953e-06 - accuracy: 1.0000 - val_loss: 2.0564e-07 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 8.9836e-05 - accuracy: 1.0000 - val_loss: 2.0365e-07 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 1.4270e-05 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 1.8913e-06 - accuracy: 1.0000 - val_loss: 1.9272e-07 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 2.7575e-06 - accuracy: 1.0000 - val_loss: 1.9073e-07 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 5.5835e-06 - accuracy: 1.0000 - val_loss: 1.9173e-07 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 9.5465e-07 - accuracy: 1.0000 - val_loss: 1.9173e-07 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 6.5926e-06 - accuracy: 1.0000 - val_loss: 1.8775e-07 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 9.1889e-07 - accuracy: 1.0000 - val_loss: 1.8477e-07 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 4.2319e-07 - accuracy: 1.0000 - val_loss: 1.8080e-07 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 4.4902e-07 - accuracy: 1.0000 - val_loss: 1.7881e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "modelss.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "r2 = modelss.fit_generator(train_set, validation_data=test_set, epochs=200, steps_per_epoch=len(train_set), validation_steps=len(test_set))\n",
    "x=r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=r2\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7Z6kR_kh4BN"
   },
   "outputs": [],
   "source": [
    "modelss.save('/content/drive/MyDrive/leaf-disease/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-la9ET1Mq8K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
